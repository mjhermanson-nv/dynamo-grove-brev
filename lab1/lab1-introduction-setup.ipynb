{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9d8d5a",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction and Kubernetes-Based Deployment\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, you will:\n",
    "- Set up your personal namespace in the shared Kubernetes cluster\n",
    "- Deploy Dynamo using namespace-scoped operator on Kubernetes\n",
    "- Configure a backend engine using aggregated serving\n",
    "- Test the deployment with OpenAI-compatible API\n",
    "- Benchmark the deployment using AI-Perf\n",
    "\n",
    "## Duration: ~90 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Section 1: Environment Setup\n",
    "\n",
    "### Objectives\n",
    "- Verify Kubernetes access (shared cluster)\n",
    "- Create your personal namespace\n",
    "- Install Dynamo dependencies in your namespace\n",
    "- Set up prerequisites (kubectl, helm)\n",
    "\n",
    "### Prerequisites\n",
    "Before starting, ensure you have:\n",
    "- ‚úÖ Kubernetes cluster access (kubeconfig provided by instructor)\n",
    "- ‚úÖ `kubectl` installed (version 1.24+) or `microk8s kubectl`\n",
    "- ‚úÖ `helm` 3.x installed\n",
    "- ‚úÖ HuggingFace token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
    "\n",
    "### Step 2: Set Configuration Variables\n",
    "\n",
    "Set your configuration variables. **Replace the values below with your own:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295fb13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load environment variables from workshop-env.sh\n",
    "# These are pre-configured based on your UID to prevent port conflicts\n",
    "USER_JUPYTER_PORT = os.environ.get('USER_JUPYTER_PORT', '8888')\n",
    "USER_FRONTEND_PORT = os.environ.get('USER_FRONTEND_PORT', '10000')\n",
    "USER_FRONTEND2_PORT = os.environ.get('USER_FRONTEND2_PORT', '11000')\n",
    "USER_PROMETHEUS_PORT = os.environ.get('USER_PROMETHEUS_PORT', '19090')\n",
    "USER_GRAFANA_PORT = os.environ.get('USER_GRAFANA_PORT', '13000')\n",
    "NAMESPACE = os.environ.get('NAMESPACE', f\"dynamo-{os.environ.get('USER', 'unknown')}\")\n",
    "\n",
    "# Set workshop configuration\n",
    "os.environ['RELEASE_VERSION'] = '0.6.0'\n",
    "os.environ['NAMESPACE'] = NAMESPACE\n",
    "os.environ['HF_TOKEN'] = ''  # Replace with your HuggingFace token\n",
    "os.environ['CACHE_PATH'] = '/data/huggingface-cache'  # Shared cache path\n",
    "\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(\"üéì Lab 1: Environment Configuration\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(f\"  User:             {os.environ.get('USER')}\")\n",
    "print(f\"  Release Version:  {os.environ['RELEASE_VERSION']}\")\n",
    "print(f\"  Namespace:        {NAMESPACE}\")\n",
    "print(f\"  Cache Path:       {os.environ['CACHE_PATH']}\")\n",
    "print(\"\")\n",
    "print(\"üìå Your Assigned Ports:\")\n",
    "print(f\"  Frontend (Lab 1): {USER_FRONTEND_PORT}\")\n",
    "print(f\"  Prometheus:       {USER_PROMETHEUS_PORT}\")\n",
    "print(f\"  Grafana:          {USER_GRAFANA_PORT}\")\n",
    "print(\"\")\n",
    "print(\"üí° Use localhost:{port} in your browser (via SSH tunnel)\")\n",
    "print(\"   - Frontend API:   localhost:10000\")\n",
    "print(\"   - Prometheus:     localhost:19090\")\n",
    "print(\"   - Grafana:        localhost:13000\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d554f",
   "metadata": {},
   "source": [
    "### Step 3: Verify Kubernetes Access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Verify kubectl is installed and configured\n",
    "kubectl version --client\n",
    "\n",
    "# Check cluster connection\n",
    "kubectl cluster-info\n",
    "\n",
    "# Check GPU nodes are available (optional)\n",
    "kubectl get nodes -o custom-columns=NAME:.metadata.name,GPUs:.status.capacity.nvidia\\\\.com/gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d62dac",
   "metadata": {},
   "source": [
    "### Step 4: Create Your Personal Namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c0e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create your personal namespace\n",
    "kubectl create namespace $NAMESPACE\n",
    "\n",
    "# Verify namespace was created\n",
    "kubectl get namespace $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e4157",
   "metadata": {},
   "source": [
    "## Section 2: Install Dynamo Platform (Namespace-Scoped)\n",
    "\n",
    "### Objectives\n",
    "- Understand namespace-scoped operator deployment for shared clusters\n",
    "- Install Dynamo CRDs (if not already installed cluster-wide)\n",
    "- Install Dynamo platform (etcd, NATS, operator) in your namespace\n",
    "- Verify platform components are running\n",
    "\n",
    "### Architecture\n",
    "```\n",
    "Client ‚Üí Frontend ‚Üí Router ‚Üí Worker(s) with Backend Engine\n",
    "                        ‚Üì\n",
    "            etcd + NATS (namespace-scoped)\n",
    "                        ‚Üì\n",
    "            Dynamo Operator (namespace-scoped)\n",
    "```\n",
    "\n",
    "### Important: Shared Cluster Configuration\n",
    "\n",
    "Since we're using a **shared Kubernetes cluster**, each participant will:\n",
    "- Create their own namespace (e.g., `dynamo-<yourname>`)\n",
    "- Install a **namespace-scoped Dynamo operator** that only manages resources in your namespace\n",
    "- The CRDs are cluster-wide and should already be installed (check first)\n",
    "\n",
    "### Step 1: Check if Dynamo CRDs Are Installed\n",
    "\n",
    "**Note:** CRDs are cluster-wide resources and only need to be installed **once per cluster**. If already installed, skip to Step 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63010df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check if CRDs already exist\n",
    "if kubectl get crd dynamographdeployments.nvidia.com &>/dev/null && \\\n",
    "   kubectl get crd dynamocomponentdeployments.nvidia.com &>/dev/null; then\n",
    "    echo \"‚úì CRDs already installed\"\n",
    "    kubectl get crd | grep nvidia.com\n",
    "else\n",
    "    echo \"‚ö†Ô∏è  CRDs not found. Ask instructor to install them, or proceed with Step 1b\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9f290",
   "metadata": {},
   "source": [
    "### Step 1b: Install CRDs (Optional - Instructor May Do This)\n",
    "\n",
    "**Skip this step if CRDs are already installed.** If needed, run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install Dynamo CRDs (only if not already installed)\n",
    "echo \"Installing Dynamo CRDs...\"\n",
    "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-crds-$RELEASE_VERSION.tgz\n",
    "helm install dynamo-crds dynamo-crds-$RELEASE_VERSION.tgz --namespace default\n",
    "\n",
    "echo \"\"\n",
    "echo \"Verifying CRD installation:\"\n",
    "kubectl get crd | grep nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ec4d2",
   "metadata": {},
   "source": [
    "### Step 2: Install Namespace-Scoped Dynamo Platform\n",
    "\n",
    "This installs ETCD, NATS, and the Dynamo Operator Controller in your namespace with namespace restriction enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Download platform chart\n",
    "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-platform-$RELEASE_VERSION.tgz\n",
    "\n",
    "# Install with namespace restriction enabled (IMPORTANT for shared clusters!)\n",
    "echo \"Installing Dynamo platform in namespace: $NAMESPACE\"\n",
    "helm install dynamo-platform dynamo-platform-$RELEASE_VERSION.tgz \\\n",
    "  --namespace $NAMESPACE \\\n",
    "  --set dynamo-operator.namespaceRestriction.enabled=true \\\n",
    "  --set metrics.enabled=false\n",
    "\n",
    "echo \"\"\n",
    "echo \"Platform installation initiated. Waiting for pods to be ready...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6ef46",
   "metadata": {},
   "source": [
    "### Step 3: Wait for Platform Pods to Be Ready\n",
    "\n",
    "Re-run the following cell until all pods report as \"Running\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl get pods -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef53d7",
   "metadata": {},
   "source": [
    "### Step 4: Create HuggingFace Token Secret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create HuggingFace token secret\n",
    "kubectl create secret generic hf-token-secret \\\n",
    "  --from-literal=HF_TOKEN=\"\" \\\n",
    "  --namespace $NAMESPACE\n",
    "\n",
    "# Verify secret was created\n",
    "kubectl get secret hf-token-secret -n $NAMESPACE\n",
    "echo \"‚úì HuggingFace token secret created\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24676ac1",
   "metadata": {},
   "source": [
    "## Section 3: Deploy Your First Model with Aggregated Serving\n",
    "\n",
    "### Objectives\n",
    "- Understand aggregated serving architecture\n",
    "- Configure and deploy a model using vLLM backend\n",
    "- Use Kubernetes manifests to deploy Dynamo resources\n",
    "\n",
    "### Available Backends\n",
    "In this lab, we'll use **vLLM** with aggregated serving for simplicity:\n",
    "- **vLLM**: High-throughput serving with PagedAttention\n",
    "- Model: `Qwen/Qwen2.5-1.5B-Instruct` (small, fast to download)\n",
    "- Architecture: Aggregated serving with KV-cache routing\n",
    "\n",
    "**Other backends** (for exploration):\n",
    "- **SGLang**: Optimized for complex prompting and structured generation\n",
    "- **TensorRT-LLM**: Maximum performance on NVIDIA GPUs\n",
    "\n",
    "### Deployment Configuration\n",
    "\n",
    "We'll use a `DynamoGraphDeployment` resource that defines:\n",
    "- **Frontend**: OpenAI-compatible API endpoint with KV-cache routing\n",
    "- **Worker**: vLLM worker with 1 GPU running the model\n",
    "\n",
    "### Step 1: Update the Deployment Configuration\n",
    "\n",
    "Before deploying, we need to update the YAML configuration with your specific values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Update agg_router.yaml with your configuration\n",
    "\n",
    "# Replace my-tag with actual version\n",
    "sed -i \"s/my-tag/$RELEASE_VERSION/g\" agg_router.yaml\n",
    "\n",
    "# Replace cache path\n",
    "sed -i \"s|/YOUR/LOCAL/CACHE/FOLDER|$CACHE_PATH|g\" agg_router.yaml\n",
    "\n",
    "echo \"‚úì Configuration updated in agg_router.yaml\"\n",
    "echo \"\"\n",
    "echo \"Verify image tags (should show version, not my-tag):\"\n",
    "grep \"image:\" agg_router.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b6bde4",
   "metadata": {},
   "source": [
    "### Step 2: Deploy the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1976760",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Apply the deployment\n",
    "kubectl apply -f agg_router.yaml --namespace $NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úì Deployment created. This will take 4-6 minutes for first run.\"\n",
    "echo \"  - Pulling container images\"\n",
    "echo \"  - Downloading model from HuggingFace\"\n",
    "echo \"  - Loading model into GPU memory\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112fc5b0",
   "metadata": {},
   "source": [
    "### Step 3: Monitor Deployment Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check deployment status\n",
    "kubectl get dynamographdeployment -n $NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"Pod status (wait for all pods to be 1/1 Ready):\"\n",
    "kubectl get pods -n $NAMESPACE | grep vllm\n",
    "\n",
    "# To watch in real-time, uncomment the line below:\n",
    "# kubectl get pods -n $NAMESPACE -w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b880d9d8",
   "metadata": {},
   "source": [
    "### Step 4: View Worker Logs (Optional)\n",
    "\n",
    "While waiting for the deployment, you can watch the model loading progress:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get logs from the worker pod\n",
    "WORKER_POD=$(kubectl get pods -n $NAMESPACE | grep vllmdecodeworker | head -1 | awk '{print $1}')\n",
    "\n",
    "if [ -n \"$WORKER_POD\" ]; then\n",
    "    echo \"Viewing logs from: $WORKER_POD\"\n",
    "    echo \"Look for:\"\n",
    "    echo \"  - 'Loading model weights...' (downloading)\"\n",
    "    echo \"  - 'Model loading took X.XX GiB' (loaded)\"\n",
    "    echo \"\"\n",
    "    kubectl logs $WORKER_POD -n $NAMESPACE --tail=30\n",
    "else\n",
    "    echo \"Worker pod not found yet, please wait and try again\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7007a",
   "metadata": {},
   "source": [
    "## Section 4: Testing and Validation\n",
    "\n",
    "### Objectives\n",
    "- Expose the service locally using port forwarding\n",
    "- Send test requests to the deployment\n",
    "- Verify OpenAI API compatibility\n",
    "- Test streaming and non-streaming responses\n",
    "\n",
    "### Testing Strategy\n",
    "Once your deployment is running (`1/1 Ready`), you'll:\n",
    "1. Forward the frontend service port to localhost\n",
    "2. Test with curl commands\n",
    "3. Verify response format and functionality\n",
    "\n",
    "### Step 1: Set Up Port Forwarding\n",
    "\n",
    "Forward the service port to localhost (run in background):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "# Forward the service port (run in background)\n",
    "kubectl port-forward deployment/vllm-agg-router-frontend $USER_FRONTEND_PORT:8000 -n $NAMESPACE &\n",
    "\n",
    "echo \"‚úì Port forward started on localhost:${USER_FRONTEND_PORT}\"\n",
    "echo \"  (To stop: use 'pkill -f port-forward' or press Ctrl+C)\"\n",
    "sleep 5  # Give it time to start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6141a0d",
   "metadata": {},
   "source": [
    "### Step 2: Test the `/v1/models` Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c42a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl http://localhost:${USER_FRONTEND_PORT}/v1/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7ae34",
   "metadata": {},
   "source": [
    "### Step 3: Simple Non-Streaming Chat Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:${USER_FRONTEND_PORT}/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{ \\\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\\\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello! How are you?\"}], \\\n",
    "    \"stream\": false,\\\n",
    "    \"max_tokens\": 50 \\\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c0942",
   "metadata": {},
   "source": [
    "### Step 4: Test Streaming Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdedabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:${USER_FRONTEND_PORT}/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{ \\\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\", \\\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Write a short poem about AI\"}], \\\n",
    "    \"stream\": true, \\\n",
    "    \"max_tokens\": 100 \\\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b99531",
   "metadata": {},
   "source": [
    "### Step 5: Test with Different Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:${USER_FRONTEND_PORT}/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{ \\\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\", \\\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain quantum computing in one sentence\"}], \\\n",
    "    \"stream\": false, \\\n",
    "    \"temperature\": 0.7, \\\n",
    "    \"max_tokens\": 100, \\\n",
    "    \"top_p\": 0.9 \\\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7844b92",
   "metadata": {},
   "source": [
    "## Section 5: Benchmarking with AI-Perf\n",
    "\n",
    "### Objectives\n",
    "- Install and configure AI-Perf benchmarking tool\n",
    "- Run performance benchmarks against your Kubernetes deployment\n",
    "- Analyze throughput, latency, and token metrics\n",
    "- Compare performance across different configurations\n",
    "\n",
    "### Metrics to Measure\n",
    "- Throughput (requests/second, tokens/second)\n",
    "- Latency (TTFT - Time To First Token, TPOT - Time Per Output Token, end-to-end)\n",
    "- GPU utilization\n",
    "- KV cache efficiency\n",
    "\n",
    "### Benchmarking Setup\n",
    "You'll run AI-Perf from your local machine against the port-forwarded service, simulating:\n",
    "- Different concurrency levels (fixed concurrent requests)\n",
    "- Request rate patterns (requests per second)\n",
    "- Various workload characteristics\n",
    "\n",
    "### Step 1: Install AI-Perf (if not already installed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AI-Perf benchmarking tool\n",
    "!uv pip install aiperf -q\n",
    "print(\"‚úì AI-Perf installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b57aa4f",
   "metadata": {},
   "source": [
    "### Step 2: Run Baseline Benchmark (Low Concurrency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d52e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run a simple benchmark with low concurrency\n",
    "aiperf profile \\\n",
    "  --model Qwen/Qwen2.5-1.5B-Instruct \\\n",
    "  --url http://localhost:${USER_FRONTEND_PORT} \\\n",
    "  --endpoint-type chat \\\n",
    "  --streaming \\\n",
    "  --concurrency 1 \\\n",
    "  --request-count 100\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úì Baseline benchmark complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fbb09",
   "metadata": {},
   "source": [
    "### Step 3: Run Benchmark with Higher Concurrency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Test with higher concurrency to stress test\n",
    "aiperf profile \\\n",
    "  --model Qwen/Qwen2.5-1.5B-Instruct \\\n",
    "  --url http://localhost:${USER_FRONTEND_PORT} \\\n",
    "  --endpoint-type chat \\\n",
    "  --streaming \\\n",
    "  --concurrency 4 \\\n",
    "  --request-count 200\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úì High concurrency benchmark complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831b797",
   "metadata": {},
   "source": [
    "### Step 4: Run Benchmark with Request Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37740db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Test with request rate instead of concurrency\n",
    "aiperf profile \\\n",
    "  --model Qwen/Qwen2.5-1.5B-Instruct \\\n",
    "  --url http://localhost:${USER_FRONTEND_PORT} \\\n",
    "  --endpoint-type chat \\\n",
    "  --streaming \\\n",
    "  --request-rate 10 \\\n",
    "  --request-count 200\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úì Request rate benchmark complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9d9f7",
   "metadata": {},
   "source": [
    "### Step 5: Analyze Results\n",
    "\n",
    "Review the benchmark outputs above. Key metrics to look for:\n",
    "- **Throughput**: requests/second and tokens/second\n",
    "- **TTFT (Time To First Token)**: How quickly does the first token appear?\n",
    "- **TPOT (Time Per Output Token)**: Generation speed\n",
    "- **End-to-end latency**: Total request time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc2b7d3",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "When you're done with Lab 1, clean up your deployment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ef724",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Delete the deployment\n",
    "kubectl delete dynamographdeployment vllm-agg-router -n $NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úì Deployment deleted\"\n",
    "echo \"Verifying pods are terminating:\"\n",
    "kubectl get pods -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738cf86b",
   "metadata": {},
   "source": [
    "**Note:** Keep your namespace and platform for Lab 2! Only delete the deployment, not the namespace.\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Check Pod Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12686a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check all pods in your namespace\n",
    "kubectl get pods -n $NAMESPACE\n",
    "\n",
    "# Describe a specific pod to see errors\n",
    "# Replace <pod-name> with actual pod name from above output\n",
    "# kubectl describe pod <pod-name> -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f6de5",
   "metadata": {},
   "source": [
    "### View Pod Logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889efc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# View logs from a specific component\n",
    "# For frontend:\n",
    "kubectl logs -l component=Frontend -n $NAMESPACE --tail=50\n",
    "\n",
    "# For worker:\n",
    "kubectl logs -l component=VllmDecodeWorker -n $NAMESPACE --tail=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12f8d7",
   "metadata": {},
   "source": [
    "### Check Deployment Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad46684",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check DynamoGraphDeployment status\n",
    "kubectl describe dynamographdeployment vllm-agg-router -n $NAMESPACE\n",
    "\n",
    "# Check operator logs\n",
    "kubectl logs -l app.kubernetes.io/name=dynamo-operator -n $NAMESPACE --tail=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2d97e",
   "metadata": {},
   "source": [
    "### Check Recent Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# View recent events in your namespace\n",
    "kubectl get events -n $NAMESPACE --sort-by='.lastTimestamp' | tail -20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28c080",
   "metadata": {},
   "source": [
    "### Common Issues\n",
    "\n",
    "1. **ImagePullBackOff**: Check if you have access to NGC containers. Verify image version is correct.\n",
    "2. **Pods stuck in Pending**: Check if GPU resources are available: `kubectl describe pod <pod-name> -n $NAMESPACE`\n",
    "3. **Model download slow**: First run takes longer due to model download. Check worker logs for progress.\n",
    "4. **Port forward not working**: Make sure pods are `1/1 Ready` before forwarding. Kill existing port-forward processes: `pkill -f port-forward`\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What You Learned\n",
    "- ‚úÖ How to set up a namespace-scoped Dynamo deployment on Kubernetes\n",
    "- ‚úÖ Kubernetes-based aggregated deployment architecture\n",
    "- ‚úÖ Creating and managing DynamoGraphDeployment resources\n",
    "- ‚úÖ Backend engine deployment (vLLM)\n",
    "- ‚úÖ Testing with OpenAI-compatible API\n",
    "- ‚úÖ Performance benchmarking with AI-Perf\n",
    "\n",
    "### Key Takeaways\n",
    "- Namespace-scoped operators enable safe multi-tenant deployments\n",
    "- Aggregated serving is simpler to deploy and suitable for single-node models\n",
    "- KV-cache routing provides intelligent load balancing across replicas\n",
    "- DynamoGraphDeployment CRD simplifies complex inference deployments\n",
    "- AI-Perf provides comprehensive performance insights\n",
    "\n",
    "### Next Steps\n",
    "- **(Optional)** Complete the **Monitoring Extension** (`lab1-monitoring.md`) to set up Prometheus and Grafana for observability\n",
    "- In **Lab 2**, you'll explore disaggregated serving with separate prefill and decode workers, and use AIConfigurator to optimize configurations for larger models\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix: Step-by-Step Commands\n",
    "\n",
    "This appendix provides complete commands for each section. Use these as a reference during the lab.\n",
    "\n",
    "**Note for MicroK8s users:** Replace `kubectl` with `microk8s kubectl` in all commands below, or set up an alias:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "alias kubectl='microk8s kubectl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773fc05",
   "metadata": {},
   "source": [
    "### A1. Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "# Verify kubectl is installed and configured\n",
    "kubectl version --client\n",
    "kubectl cluster-info\n",
    "\n",
    "# Set your configuration (customize with your name!)\n",
    "export NAMESPACE=\"dynamo-yourname\"  # Replace 'yourname' with your actual name\n",
    "export RELEASE_VERSION=\"0.5.0\"     # Dynamo version\n",
    "export HF_TOKEN=\"your_hf_token\"    # Your HuggingFace token\n",
    "export CACHE_PATH=\"/data/huggingface-cache\"  # Shared cache path (ask instructor)\n",
    "\n",
    "# Create your personal namespace\n",
    "kubectl create namespace ${NAMESPACE}\n",
    "\n",
    "# Verify namespace was created\n",
    "kubectl get namespace ${NAMESPACE}\n",
    "\n",
    "# Check GPU nodes are available (optional)\n",
    "kubectl get nodes -o custom-columns=NAME:.metadata.name,GPUs:.status.capacity.nvidia\\\\.com/gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e64573",
   "metadata": {},
   "source": [
    "### A2. Install Dynamo Platform (Namespace-Scoped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdccc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "# Step 1: Check if CRDs are already installed (cluster-wide)\n",
    "if kubectl get crd dynamographdeployments.nvidia.com &>/dev/null && \\\n",
    "   kubectl get crd dynamocomponentdeployments.nvidia.com &>/dev/null; then\n",
    "    echo \"‚úì CRDs already installed\"\n",
    "else\n",
    "    echo \"‚ö†Ô∏è  CRDs not found. Ask instructor to install them, or run:\"\n",
    "    echo \"helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-crds-${RELEASE_VERSION}.tgz\"\n",
    "    echo \"helm install dynamo-crds dynamo-crds-${RELEASE_VERSION}.tgz --namespace default\"\n",
    "fi\n",
    "\n",
    "# Step 2: Download Dynamo platform helm chart\n",
    "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-platform-${RELEASE_VERSION}.tgz\n",
    "\n",
    "# Step 3: Install namespace-scoped Dynamo platform\n",
    "# IMPORTANT: --set dynamo-operator.namespaceRestriction.enabled=true restricts operator to this namespace\n",
    "helm install dynamo-platform dynamo-platform-${RELEASE_VERSION}.tgz \\\n",
    "  --namespace ${NAMESPACE} \\\n",
    "  --set dynamo-operator.namespaceRestriction.enabled=true\n",
    "\n",
    "# Step 4: Wait for platform pods to be ready (~2-3 minutes)\n",
    "echo \"Waiting for platform pods to be ready...\"\n",
    "kubectl wait --for=condition=ready pod \\\n",
    "  --all \\\n",
    "  --namespace ${NAMESPACE} \\\n",
    "  --timeout=300s\n",
    "\n",
    "# Step 5: Verify platform is running\n",
    "kubectl get pods -n ${NAMESPACE}\n",
    "# You should see: dynamo-operator, etcd, and nats pods in Running state\n",
    "\n",
    "# Step 6: Create HuggingFace token secret\n",
    "kubectl create secret generic hf-token-secret \\\n",
    "  --from-literal=HF_TOKEN=\"${HF_TOKEN}\" \\\n",
    "  --namespace ${NAMESPACE}\n",
    "\n",
    "# Verify secret was created\n",
    "kubectl get secret hf-token-secret -n ${NAMESPACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b19e2",
   "metadata": {},
   "source": [
    "### A3. Deploy Your First Model\n",
    "\n",
    "Create a deployment YAML file `agg_router.yaml`:\n",
    "\n",
    "```yaml\n",
    "# agg_router.yaml\n",
    "apiVersion: nvidia.com/v1alpha1\n",
    "kind: DynamoGraphDeployment\n",
    "metadata:\n",
    "  name: vllm-agg-router\n",
    "spec:\n",
    "  services:\n",
    "    Frontend:\n",
    "      dynamoNamespace: vllm-agg-router\n",
    "      componentType: frontend\n",
    "      replicas: 1\n",
    "      extraPodSpec:\n",
    "        mainContainer:\n",
    "          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.5.0\n",
    "      envs:\n",
    "        - name: DYN_ROUTER_MODE\n",
    "          value: kv\n",
    "    VllmDecodeWorker:\n",
    "      envFromSecret: hf-token-secret\n",
    "      dynamoNamespace: vllm-agg-router\n",
    "      componentType: worker\n",
    "      replicas: 1\n",
    "      resources:\n",
    "        limits:\n",
    "          gpu: \"1\"\n",
    "      envs:\n",
    "        - name: DYN_LOG\n",
    "          value: \"info\"\n",
    "      extraPodSpec:\n",
    "        volumes:\n",
    "        - name: local-model-cache\n",
    "          hostPath:\n",
    "            path: /data/huggingface-cache  # Update if instructor provides different path\n",
    "            type: DirectoryOrCreate\n",
    "        mainContainer:\n",
    "          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.5.0\n",
    "          volumeMounts:\n",
    "          - name: local-model-cache\n",
    "            mountPath: /root/.cache\n",
    "          workingDir: /workspace/components/backends/vllm\n",
    "          command:\n",
    "            - /bin/sh\n",
    "            - -c\n",
    "          args:\n",
    "            - python3 -m dynamo.vllm --model Qwen/Qwen2.5-1.5B-Instruct\n",
    "```\n",
    "\n",
    "Deploy the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7053f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "# Apply the deployment\n",
    "kubectl apply -f agg_router.yaml --namespace ${NAMESPACE}\n",
    "\n",
    "# Monitor deployment progress\n",
    "kubectl get dynamographdeployment -n ${NAMESPACE}\n",
    "\n",
    "# Watch pods starting up (this takes 4-6 minutes for first run)\n",
    "kubectl get pods -n ${NAMESPACE} -w\n",
    "# Press Ctrl+C to stop watching\n",
    "\n",
    "# Check specific pod status\n",
    "kubectl get pods -n ${NAMESPACE} | grep vllm\n",
    "\n",
    "# View worker logs to see model loading progress\n",
    "WORKER_POD=$(kubectl get pods -n ${NAMESPACE} | grep vllmdecodeworker | head -1 | awk '{print $1}')\n",
    "kubectl logs ${WORKER_POD} -n ${NAMESPACE} --tail=50 --follow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e8a55",
   "metadata": {},
   "source": [
    "### A4. Test the Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "# Forward the frontend service port (run in a separate terminal, or add & to background)\n",
    "kubectl port-forward deployment/vllm-agg-router-frontend $USER_FRONTEND_PORT:8000 -n ${NAMESPACE}\n",
    "\n",
    "# In another terminal, test the deployment:\n",
    "\n",
    "# Test 1: Check available models\n",
    "curl http://localhost:${USER_FRONTEND_PORT}/v1/models\n",
    "\n",
    "# Test 2: Simple non-streaming chat completion\n",
    "curl http://localhost:${USER_FRONTEND_PORT}/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello! How are you?\"}],\n",
    "    \"stream\": false,\n",
    "    \"max_tokens\": 50\n",
    "  }'\n",
    "\n",
    "# Test 3: Streaming chat completion\n",
    "curl http://localhost:${USER_FRONTEND_PORT}/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Write a short poem about AI\"}],\n",
    "    \"stream\": true,\n",
    "    \"max_tokens\": 100\n",
    "  }'\n",
    "\n",
    "# Test 4: With different parameters\n",
    "curl http://localhost:${USER_FRONTEND_PORT}/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain quantum computing in one sentence\"}],\n",
    "    \"stream\": false,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 100,\n",
    "    \"top_p\": 0.9\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9d433",
   "metadata": {},
   "source": [
    "### A5. Benchmark with AI-Perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AI-Perf (if not already installed)\n",
    "pip install aiperf\n",
    "\n",
    "# Run a simple benchmark (adjust parameters as needed)\n",
    "aiperf profile \\\n",
    "  --model Qwen/Qwen2.5-1.5B-Instruct \\\n",
    "  --url http://localhost:${USER_FRONTEND_PORT} \\\n",
    "  --endpoint-type chat \\\n",
    "  --streaming \\\n",
    "  --concurrency 1 \\\n",
    "  --request-count 100\n",
    "\n",
    "# Run with higher concurrency\n",
    "aiperf profile \\\n",
    "  --model Qwen/Qwen2.5-1.5B-Instruct \\\n",
    "  --url http://localhost:${USER_FRONTEND_PORT} \\\n",
    "  --endpoint-type chat \\\n",
    "  --streaming \\\n",
    "  --concurrency 4 \\\n",
    "  --request-count 200\n",
    "\n",
    "# Run with request rate\n",
    "aiperf profile \\\n",
    "  --model Qwen/Qwen2.5-1.5B-Instruct \\\n",
    "  --url http://localhost:${USER_FRONTEND_PORT} \\\n",
    "  --endpoint-type chat \\\n",
    "  --streaming \\\n",
    "  --request-rate 10 \\\n",
    "  --request-count 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a43ed",
   "metadata": {},
   "source": [
    "### A6. Scale Your Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "# Edit your agg_router.yaml and change replicas from 1 to 2\n",
    "# Then reapply:\n",
    "kubectl apply -f agg_router.yaml --namespace ${NAMESPACE}\n",
    "\n",
    "# Watch the new worker come online\n",
    "kubectl get pods -n ${NAMESPACE} -w\n",
    "\n",
    "# Test that load is distributed (KV-cache routing should work)\n",
    "# Run multiple requests and check logs from both workers\n",
    "kubectl logs -l component=VllmDecodeWorker -n ${NAMESPACE} --tail=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24437fa",
   "metadata": {},
   "source": [
    "### A7. Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "# Delete the deployment\n",
    "kubectl delete dynamographdeployment vllm-agg-router -n ${NAMESPACE}\n",
    "\n",
    "# Verify pods are terminating\n",
    "kubectl get pods -n ${NAMESPACE}\n",
    "\n",
    "# (Optional) Keep your namespace for Lab 2\n",
    "# To completely clean up (only if you're done with all labs):\n",
    "# kubectl delete namespace ${NAMESPACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a8128",
   "metadata": {},
   "source": [
    "### A8. Troubleshooting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ec0a0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%python\n",
    "# Check pod status\n",
    "kubectl get pods -n ${NAMESPACE}\n",
    "\n",
    "# Describe a pod to see errors\n",
    "kubectl describe pod <pod-name> -n ${NAMESPACE}\n",
    "\n",
    "# View logs from a specific pod\n",
    "kubectl logs <pod-name> -n ${NAMESPACE}\n",
    "\n",
    "# Check DynamoGraphDeployment status\n",
    "kubectl describe dynamographdeployment vllm-agg-router -n ${NAMESPACE}\n",
    "\n",
    "# Check operator logs\n",
    "kubectl logs -l app.kubernetes.io/name=dynamo-operator -n ${NAMESPACE}\n",
    "\n",
    "# Check if image pull is working\n",
    "kubectl get events -n ${NAMESPACE} --sort-by='.lastTimestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372798df",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "bash",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
