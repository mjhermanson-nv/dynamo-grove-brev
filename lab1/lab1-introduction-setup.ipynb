{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fac2f6a",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction and Kubernetes-Based Deployment\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, you will:\n",
    "- Set up Kubernetes cluster with Dynamo platform\n",
    "- Deploy Dynamo using cluster-wide operator (recommended)\n",
    "- Configure a backend engine using disaggregated serving\n",
    "- Test the deployment with OpenAI-compatible API\n",
    "- Benchmark the deployment using AI-Perf\n",
    "\n",
    "## Duration: ~90 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Section 1: Environment Setup\n",
    "\n",
    "### Objectives\n",
    "- Verify Kubernetes access \n",
    "- Install Dynamo dependencies\n",
    "- Set up prerequisites (kubectl, helm)\n",
    "\n",
    "### Prerequisites\n",
    "Before starting, ensure you have:\n",
    "- ‚úÖ Kubernetes cluster access (kubeconfig provided by instructor)\n",
    "- ‚úÖ `kubectl` installed (version 1.24+) or `microk8s kubectl`\n",
    "- ‚úÖ `helm` 3.x installed\n",
    "- ‚úÖ HuggingFace token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
    "\n",
    "### Step 2: Set Configuration Variables\n",
    "\n",
    "Set your configuration variables. **Replace the values below with your own:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Set environment variables (use defaults if not already set)\n",
    "export RELEASE_VERSION=${RELEASE_VERSION:-0.7.1}\n",
    "export NAMESPACE=${NAMESPACE:-dynamo}\n",
    "export CACHE_PATH=${CACHE_PATH:-/data/huggingface-cache}\n",
    "\n",
    "# Get node IP\n",
    "NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}')\n",
    "\n",
    "echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\n",
    "echo \"üéì Lab 1: Environment Configuration\"\n",
    "echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\"\n",
    "echo \"  Release Version:  $RELEASE_VERSION\"\n",
    "echo \"  Namespace:        $NAMESPACE\"\n",
    "echo \"  Cache Path:       $CACHE_PATH\"\n",
    "echo \"  Node IP:          $NODE_IP\"\n",
    "echo \"\"\n",
    "echo \"üìå Service Ports (after deployment):\"\n",
    "echo \"  Frontend API:     http://$NODE_IP:30100\"\n",
    "echo \"  Grafana:          http://$NODE_IP:30080\"\n",
    "echo \"\"\n",
    "echo \"üí° Note: Frontend will be accessible after deploying in Section 3\"\n",
    "echo \"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801210b",
   "metadata": {},
   "source": [
    "### Step 3: Verify Kubernetes Access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f48063",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Verify kubectl is installed and configured\n",
    "echo \"=== kubectl version ===\"\n",
    "kubectl version --client\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Cluster info ===\"\n",
    "kubectl cluster-info\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== GPU nodes ===\"\n",
    "kubectl get nodes -o custom-columns=NAME:.metadata.name,GPUs:.status.capacity.nvidia\\\\.com/gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d06bbb1",
   "metadata": {},
   "source": [
    "### Step 4: Set Up NGC Authentication\n",
    "\n",
    "To access NVIDIA's Dynamo container images, you need to authenticate with NGC (NVIDIA GPU Cloud).\n",
    "\n",
    "#### Get Your NGC API Key\n",
    "\n",
    "1. Go to [NGC](https://ngc.nvidia.com/)\n",
    "2. Sign in or create an account\n",
    "3. Click on your profile in the top right corner\n",
    "4. Select **\"Setup\"** ‚Üí **\"Generate API Key\"**\n",
    "5. Copy your API key (it will only be shown once!)\n",
    "\n",
    "#### Set NGC API Key\n",
    "\n",
    "**Get your NGC API Key from [ngc.nvidia.com](https://ngc.nvidia.com/)** (Go to Profile > Setup > Generate API Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c82394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Get NGC API key from user\n",
    "print(\"Enter your NGC API Key from https://ngc.nvidia.com/\")\n",
    "print(\"(Go to Profile > Setup > Generate API Key)\")\n",
    "print(\"\")\n",
    "NGC_API_KEY = getpass.getpass(\"NGC API Key: \")\n",
    "\n",
    "# Save it for later use (creating pull secrets)\n",
    "os.environ['NGC_API_KEY'] = NGC_API_KEY\n",
    "\n",
    "print(\"\")\n",
    "print(\"‚úì NGC API key saved\")\n",
    "print(\"  You can now use it to login and create pull secrets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88bd204",
   "metadata": {},
   "source": [
    "#### Set HuggingFace Token\n",
    "\n",
    "**HuggingFace token is required to download models.** Get yours from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) (Create a 'Read' token if you don't have one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ac538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Get HuggingFace token from user\n",
    "print(\"Enter your HuggingFace Token from https://huggingface.co/settings/tokens\")\n",
    "print(\"(Create a 'Read' token if you don't have one)\")\n",
    "print(\"\")\n",
    "HF_TOKEN = getpass.getpass(\"HF Token: \")\n",
    "\n",
    "# Save it for later use\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN\n",
    "\n",
    "print(\"\")\n",
    "print(\"‚úì HuggingFace token saved to environment\")\n",
    "print(\"  Available as $HF_TOKEN in bash cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5514f82",
   "metadata": {},
   "source": [
    "#### Login to NGC Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f28d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Login to NGC container registry\n",
    "echo \"$NGC_API_KEY\" | helm registry login nvcr.io --username '$oauthtoken' --password-stdin\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úì NGC authentication complete\"\n",
    "echo \"  You can now pull Dynamo container images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd656705",
   "metadata": {},
   "source": [
    "### Step 5: Create Your Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create the namespace\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "kubectl create namespace $NAMESPACE 2>&1 | grep -v \"AlreadyExists\" || true\n",
    "\n",
    "# Verify namespace was created\n",
    "echo \"\"\n",
    "echo \"Verifying namespace:\"\n",
    "kubectl get namespace $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e5c77",
   "metadata": {},
   "source": [
    "### Step 6: Create NGC Pull Secret\n",
    "\n",
    "Create a Kubernetes secret so that pods can pull images from NGC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ace4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get variables\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# Create NGC image pull secret\n",
    "kubectl create secret docker-registry ngc-secret \\\n",
    "    --docker-server=nvcr.io \\\n",
    "    --docker-username='$oauthtoken' \\\n",
    "    --docker-password=\"$NGC_API_KEY\" \\\n",
    "    --namespace $NAMESPACE \\\n",
    "    2>&1 | grep -v \"AlreadyExists\" || true\n",
    "\n",
    "# Verify secret was created\n",
    "echo \"\"\n",
    "echo \"Verifying NGC secret:\"\n",
    "kubectl get secret ngc-secret -n $NAMESPACE\n",
    "echo \"‚úì NGC pull secret created in namespace: $NAMESPACE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333a704",
   "metadata": {},
   "source": [
    "### Step 7: Create HuggingFace Token Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fcce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get variables\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# Create HuggingFace token secret\n",
    "kubectl create secret generic hf-token-secret \\\n",
    "    --from-literal=HF_TOKEN=\"$HF_TOKEN\" \\\n",
    "    --namespace $NAMESPACE \\\n",
    "    2>&1 | grep -v \"AlreadyExists\" || true\n",
    "\n",
    "# Verify secret was created\n",
    "echo \"\"\n",
    "echo \"Verifying HuggingFace secret:\"\n",
    "kubectl get secret hf-token-secret -n $NAMESPACE\n",
    "echo \"‚úì HuggingFace token secret created\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c48155",
   "metadata": {},
   "source": [
    "## Section 2: Install Dynamo Platform\n",
    "\n",
    "### Objectives\n",
    "- Install Dynamo CRDs (Custom Resource Definitions)\n",
    "- Install Dynamo platform (etcd, NATS, operator) \n",
    "- Verify platform components are running\n",
    "\n",
    "### Architecture\n",
    "```\n",
    "Client Request\n",
    "      ‚Üì\n",
    "Frontend (OpenAI API + Disaggregated Router)\n",
    "      ‚Üì\n",
    "Prefill Worker (GPU 0) ‚Üí Processes prompt ‚Üí Generates KV cache\n",
    "      ‚Üì\n",
    "Decode Worker (GPU 1) ‚Üí Uses KV cache ‚Üí Generates tokens\n",
    "      ‚Üì\n",
    "      ‚Üì\n",
    "   etcd + NATS (Coordination & Messaging)\n",
    "      ‚Üì\n",
    "Dynamo Operator (Manages Resources)\n",
    "```\n",
    "\n",
    "### Deployment Mode\n",
    "\n",
    "We're using the **recommended cluster-wide deployment** (default). According to the [official Dynamo documentation](https://github.com/ai-dynamo/dynamo/blob/main/deploy/helm/charts/platform/README.md):\n",
    "\n",
    "- ‚úÖ **Recommended**: One cluster-wide operator per cluster (default)\n",
    "- This is the standard deployment for single-node and production clusters\n",
    "- Install a **namespace-scoped Dynamo operator** that only manages resources in your namespace\n",
    "- The CRDs are cluster-wide and should already be installed (check first)\n",
    "\n",
    "### Step 1: Check if Dynamo CRDs Are Installed\n",
    "\n",
    "**Note:** CRDs are cluster-wide resources and only need to be installed **once per cluster**. If already installed, skip to Step 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check if CRDs already exist\n",
    "if kubectl get crd dynamographdeployments.nvidia.com &>/dev/null && \\\n",
    "   kubectl get crd dynamocomponentdeployments.nvidia.com &>/dev/null; then\n",
    "    echo \"‚úì CRDs already installed\"\n",
    "    kubectl get crd | grep nvidia.com\n",
    "else\n",
    "    echo \"‚ö†Ô∏è  CRDs not found. Ask instructor to install them, or proceed with Step 1b\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b3e59",
   "metadata": {},
   "source": [
    "### Step 1b: Install CRDs (Optional - Instructor May Do This)\n",
    "\n",
    "**Skip this step if CRDs are already installed.** If needed, run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install Dynamo CRDs (only if not already installed)\n",
    "RELEASE_VERSION=${RELEASE_VERSION:-0.7.1}\n",
    "\n",
    "echo \"Installing Dynamo CRDs...\"\n",
    "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-crds-$RELEASE_VERSION.tgz\n",
    "helm install dynamo-crds dynamo-crds-$RELEASE_VERSION.tgz --namespace default\n",
    "\n",
    "echo \"\"\n",
    "echo \"Verifying CRD installation:\"\n",
    "kubectl get crd | grep nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b632f",
   "metadata": {},
   "source": [
    "### Step 2: Install Dynamo Platform\n",
    "\n",
    "This installs ETCD, NATS, and the Dynamo Operator Controller (cluster-wide by default).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e266fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "RELEASE_VERSION=${RELEASE_VERSION:-0.7.1}\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# Download platform chart\n",
    "echo \"Downloading Dynamo platform chart...\"\n",
    "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-platform-$RELEASE_VERSION.tgz\n",
    "\n",
    "# Install Dynamo platform (cluster-wide by default - recommended)\n",
    "echo \"Installing Dynamo platform in namespace: $NAMESPACE\"\n",
    "helm install dynamo-platform \\\n",
    "    dynamo-platform-$RELEASE_VERSION.tgz \\\n",
    "    --namespace $NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"Platform installation initiated. Waiting for pods to be ready...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4db249",
   "metadata": {},
   "source": [
    "### Step 3: Wait for Platform Pods to Be Ready\n",
    "\n",
    "Re-run the following cell until all pods report as \"Running\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a08b5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "echo \"Waiting for platform pods to be ready...\"\n",
    "echo \"\"\n",
    "\n",
    "# Wait for pods to be ready (timeout after 5 minutes)\n",
    "TIMEOUT=300\n",
    "ELAPSED=0\n",
    "INTERVAL=5\n",
    "\n",
    "while [ $ELAPSED -lt $TIMEOUT ]; do\n",
    "    # Get pod status\n",
    "    NOT_READY=$(kubectl get pods -n $NAMESPACE --no-headers 2>/dev/null | grep -v \"Running\\|Completed\" | wc -l)\n",
    "    TOTAL=$(kubectl get pods -n $NAMESPACE --no-headers 2>/dev/null | wc -l)\n",
    "    READY=$((TOTAL - NOT_READY))\n",
    "    \n",
    "    echo \"[$ELAPSED s] Pods ready: $READY/$TOTAL\"\n",
    "    kubectl get pods -n $NAMESPACE\n",
    "    \n",
    "    # Check if all pods are ready\n",
    "    if [ $NOT_READY -eq 0 ] && [ $TOTAL -gt 0 ]; then\n",
    "        echo \"\"\n",
    "        echo \"‚úì All platform pods are ready!\"\n",
    "        break\n",
    "    fi\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"Waiting for pods to be ready... (checking again in ${INTERVAL}s)\"\n",
    "    echo \"\"\n",
    "    sleep $INTERVAL\n",
    "    ELAPSED=$((ELAPSED + INTERVAL))\n",
    "done\n",
    "\n",
    "if [ $ELAPSED -ge $TIMEOUT ]; then\n",
    "    echo \"‚ö†Ô∏è  Timeout waiting for pods to be ready\"\n",
    "    echo \"Please check pod status manually: kubectl get pods -n $NAMESPACE\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cee4ad",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d281967",
   "metadata": {},
   "source": [
    "## Section 3: Deploy Your First Model with Disaggregated Serving\n",
    "\n",
    "### Objectives\n",
    "- Understand disaggregated serving architecture\n",
    "- Configure and deploy a model using vLLM backend with separate prefill and decode workers\n",
    "- Use Kubernetes manifests to deploy Dynamo resources\n",
    "\n",
    "### Available Backends\n",
    "In this lab, we'll use **vLLM** with disaggregated serving:\n",
    "- **vLLM**: High-throughput serving with PagedAttention\n",
    "- Model: `Qwen/Qwen2.5-1.5B-Instruct` (small, fast to download)\n",
    "- Architecture: Disaggregated serving with separate prefill and decode workers\n",
    "\n",
    "**Other backends** (for exploration):\n",
    "- **SGLang**: Optimized for complex prompting and structured generation\n",
    "- **TensorRT-LLM**: Maximum performance on NVIDIA GPUs\n",
    "\n",
    "### What is Disaggregated Serving?\n",
    "\n",
    "Disaggregated serving separates the inference pipeline into specialized workers:\n",
    "\n",
    "**Prefill Worker** (GPU 0):\n",
    "- Processes input prompts (compute-intensive)\n",
    "- Converts tokens into KV cache\n",
    "- Passes KV cache to decode workers\n",
    "\n",
    "**Decode Worker** (GPU 1):\n",
    "- Generates output tokens (memory-intensive)\n",
    "- Uses KV cache from prefill worker\n",
    "- Produces the final response\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ **Independent scaling**: Scale prefill and decode separately based on workload\n",
    "- ‚úÖ **Resource optimization**: Each worker optimized for its specific task\n",
    "- ‚úÖ **Better throughput**: Specialized workers can handle more requests\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Client Request\n",
    "    ‚Üì\n",
    "Frontend (Router)\n",
    "    ‚Üì\n",
    "Prefill Worker (GPU 0) ‚Üí processes prompt ‚Üí generates KV cache\n",
    "    ‚Üì\n",
    "Decode Worker (GPU 1) ‚Üí receives KV cache ‚Üí generates tokens\n",
    "    ‚Üì\n",
    "Response to Client\n",
    "```\n",
    "\n",
    "### Deployment Configuration\n",
    "\n",
    "We'll use a `DynamoGraphDeployment` resource that defines:\n",
    "- **Frontend**: OpenAI-compatible API endpoint with disaggregated routing\n",
    "- **VllmPrefillWorker**: 1 replica on GPU 0 for prompt processing\n",
    "- **VllmDecodeWorker**: 1 replica on GPU 1 for token generation\n",
    "\n",
    "### Step 1: Update the Deployment Configuration\n",
    "\n",
    "Before deploying, we need to update the YAML configuration with your specific values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b96887",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Update disagg_router.yaml with your configuration\n",
    "\n",
    "# Replace my-tag with actual version\n",
    "sed -i \"s/my-tag/$RELEASE_VERSION/g\" disagg_router.yaml\n",
    "\n",
    "# Replace cache path\n",
    "sed -i \"s|/YOUR/LOCAL/CACHE/FOLDER|$CACHE_PATH|g\" disagg_router.yaml\n",
    "\n",
    "echo \"‚úì Configuration updated in disagg_router.yaml\"\n",
    "echo \"\"\n",
    "echo \"Verify image tags (should show version, not my-tag):\"\n",
    "grep \"image:\" disagg_router.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e817cf",
   "metadata": {},
   "source": [
    "### Step 2: Deploy the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# Apply the deployment\n",
    "kubectl apply -f disagg_router.yaml --namespace $NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úì Deployment created. This will take 4-6 minutes for first run.\"\n",
    "echo \"  - Pulling container images\"\n",
    "echo \"  - Downloading model from HuggingFace\"\n",
    "echo \"  - Loading model into GPU memory\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbc1b7",
   "metadata": {},
   "source": [
    "### Step 3: Monitor Deployment Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "echo \"Expected pods:\"\n",
    "echo \"  - vllm-disagg-router-frontend-xxxxx     (Frontend)\"\n",
    "echo \"  - vllm-disagg-router-vllmprefillworker-xxxxx (Prefill Worker on GPU 0)\"\n",
    "echo \"  - vllm-disagg-router-vllmdecodeworker-xxxxx  (Decode Worker on GPU 1)\"\n",
    "echo \"\"\n",
    "echo \"Waiting for deployment pods to be ready (this may take 4-6 minutes for first run)...\"\n",
    "echo \"\"\n",
    "\n",
    "# Wait for pods to be ready (timeout after 10 minutes for model download)\n",
    "TIMEOUT=600\n",
    "ELAPSED=0\n",
    "INTERVAL=10\n",
    "\n",
    "while [ $ELAPSED -lt $TIMEOUT ]; do\n",
    "    # Get vllm pod status\n",
    "    VLLM_PODS=$(kubectl get pods -n $NAMESPACE 2>/dev/null | grep vllm || true)\n",
    "    NOT_READY=$(echo \"$VLLM_PODS\" | grep -v \"1/1.*Running\" | grep -v \"^$\" | wc -l)\n",
    "    TOTAL=$(echo \"$VLLM_PODS\" | grep -v \"^$\" | wc -l)\n",
    "    READY=$((TOTAL - NOT_READY))\n",
    "    \n",
    "    echo \"[$ELAPSED s] VLLM Pods ready: $READY/$TOTAL\"\n",
    "    kubectl get pods -n $NAMESPACE | grep -E '(NAME|vllm)'\n",
    "    \n",
    "    # Check if all vllm pods are ready\n",
    "    if [ $NOT_READY -eq 0 ] && [ $TOTAL -ge 3 ]; then\n",
    "        echo \"\"\n",
    "        echo \"‚úì All deployment pods are ready!\"\n",
    "        echo \"\"\n",
    "        echo \"DynamoGraphDeployment status:\"\n",
    "        kubectl get dynamographdeployment -n $NAMESPACE\n",
    "        break\n",
    "    fi\n",
    "    \n",
    "    echo \"\"\n",
    "    echo \"Waiting for pods to be ready... (checking again in ${INTERVAL}s)\"\n",
    "    echo \"üí° Tip: Model download happens on first run and may take 3-5 minutes\"\n",
    "    echo \"\"\n",
    "    sleep $INTERVAL\n",
    "    ELAPSED=$((ELAPSED + INTERVAL))\n",
    "done\n",
    "\n",
    "if [ $ELAPSED -ge $TIMEOUT ]; then\n",
    "    echo \"‚ö†Ô∏è  Timeout waiting for pods to be ready\"\n",
    "    echo \"Check logs: kubectl logs -l component=VllmPrefillWorker -n $NAMESPACE --tail=50\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f5ca5",
   "metadata": {},
   "source": [
    "### Step 3b: Troubleshoot Pod Issues (If Pods Are Crashing)\n",
    "\n",
    "If your pods are in `Error` or `CrashLoopBackOff` state, run this cell to diagnose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "echo \"=== Pod Status ===\"\n",
    "kubectl get pods -n $NAMESPACE | grep vllm\n",
    "echo \"\"\n",
    "\n",
    "echo \"=== GPU Availability ===\"\n",
    "kubectl get nodes -o custom-columns=NAME:.metadata.name,GPUs:.status.capacity.nvidia\\\\.com/gpu,GPU-Allocatable:.status.allocatable.nvidia\\\\.com/gpu\n",
    "echo \"\"\n",
    "\n",
    "echo \"=== Checking Secrets ===\"\n",
    "kubectl get secret hf-token-secret -n $NAMESPACE &>/dev/null && echo \"‚úì HF token secret exists\" || echo \"‚úó HF token secret missing!\"\n",
    "kubectl get secret ngc-secret -n $NAMESPACE &>/dev/null && echo \"‚úì NGC secret exists\" || echo \"‚úó NGC secret missing!\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"=== Prefill Worker Logs (last 30 lines) ===\"\n",
    "PREFILL_POD=$(kubectl get pods -n $NAMESPACE | grep vllmprefillworker | awk '{print $1}' | head -1)\n",
    "if [ -n \"$PREFILL_POD\" ]; then\n",
    "    kubectl logs $PREFILL_POD -n $NAMESPACE --tail=30\n",
    "else\n",
    "    echo \"No prefill pod found\"\n",
    "fi\n",
    "echo \"\"\n",
    "\n",
    "echo \"=== Decode Worker Logs (last 30 lines) ===\"\n",
    "DECODE_POD=$(kubectl get pods -n $NAMESPACE | grep vllmdecodeworker | awk '{print $1}' | head -1)\n",
    "if [ -n \"$DECODE_POD\" ]; then\n",
    "    kubectl logs $DECODE_POD -n $NAMESPACE --tail=30\n",
    "else\n",
    "    echo \"No decode pod found\"\n",
    "fi\n",
    "echo \"\"\n",
    "\n",
    "echo \"=== Common Issues ===\"\n",
    "echo \"1. If 'insufficient gpu' error: You need 2 GPUs for disaggregated serving\"\n",
    "echo \"2. If 'HF_TOKEN' error: Make sure you created the hf-token-secret\"\n",
    "echo \"3. If 'ImagePullBackOff': Check NGC secret and credentials\"\n",
    "echo \"4. If model download errors: Check network connectivity to huggingface.co\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6ea8c",
   "metadata": {},
   "source": [
    "### Step 4: View Worker Logs (Optional)\n",
    "\n",
    "While waiting for the deployment, you can watch the model loading progress in both workers.\n",
    "\n",
    "**Note**: In disaggregated serving, both the prefill and decode workers load the model separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364291e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# Get logs from worker pods\n",
    "PREFILL_POD=$(kubectl get pods -n $NAMESPACE | grep vllmprefillworker | awk '{print $1}' | head -1)\n",
    "DECODE_POD=$(kubectl get pods -n $NAMESPACE | grep vllmdecodeworker | awk '{print $1}' | head -1)\n",
    "\n",
    "if [ -n \"$PREFILL_POD\" ]; then\n",
    "    echo \"=== Prefill Worker Logs (GPU 0): $PREFILL_POD ===\"\n",
    "    echo \"Look for:\"\n",
    "    echo \"  - 'Loading model weights...' (downloading)\"\n",
    "    echo \"  - 'Model loading took X.XX GiB' (loaded)\"\n",
    "    echo \"\"\n",
    "    kubectl logs $PREFILL_POD -n $NAMESPACE --tail=30\n",
    "    echo \"\"\n",
    "fi\n",
    "\n",
    "if [ -n \"$DECODE_POD\" ]; then\n",
    "    echo \"=== Decode Worker Logs (GPU 1): $DECODE_POD ===\"\n",
    "    echo \"Look for:\"\n",
    "    echo \"  - 'Loading model weights...' (downloading)\"\n",
    "    echo \"  - 'Model loading took X.XX GiB' (loaded)\"\n",
    "    echo \"\"\n",
    "    kubectl logs $DECODE_POD -n $NAMESPACE --tail=30\n",
    "fi\n",
    "\n",
    "if [ -z \"$PREFILL_POD\" ] && [ -z \"$DECODE_POD\" ]; then\n",
    "    echo \"Worker pods not found yet, please wait and try again\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca76cd9",
   "metadata": {},
   "source": [
    "## Section 4: Testing and Validation\n",
    "\n",
    "### Objectives\n",
    "- Expose the service locally using port forwarding\n",
    "- Send test requests to the deployment\n",
    "- Verify OpenAI API compatibility\n",
    "- Test streaming and non-streaming responses\n",
    "\n",
    "### Testing Strategy\n",
    "Once your deployment is running (`1/1 Ready`), you'll:\n",
    "1. Forward the frontend service port to localhost\n",
    "2. Test with curl commands\n",
    "3. Verify response format and functionality\n",
    "\n",
    "### Step 1: Set Up Port Forwarding\n",
    "\n",
    "Forward the service port to localhost (run in background):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beff4f8",
   "metadata": {},
   "source": [
    "### Understanding Disaggregated Serving Trade-offs\n",
    "\n",
    "Now that your deployment is running, let's understand when and why disaggregated serving is beneficial:\n",
    "\n",
    "**When to Use Disaggregated:**\n",
    "- ‚úÖ **Large models** (70B+ parameters) where compute and memory demands differ\n",
    "- ‚úÖ **High throughput scenarios** where prefill and decode have different scaling needs\n",
    "- ‚úÖ **Long input prompts** where prefill becomes a bottleneck\n",
    "- ‚úÖ **Production deployments** with predictable traffic patterns\n",
    "\n",
    "**When Aggregated is Better:**\n",
    "- ‚úÖ **Small to medium models** (< 13B parameters) like we're using here\n",
    "- ‚úÖ **Development and testing** where simplicity matters\n",
    "- ‚úÖ **Unpredictable workloads** where flexibility is key\n",
    "- ‚úÖ **Resource-constrained environments** with limited GPUs\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "| Aspect | Aggregated | Disaggregated |\n",
    "|--------|-----------|---------------|\n",
    "| Architecture | Single worker type | Separate prefill & decode |\n",
    "| GPU Utilization | Both phases on same GPU | Specialized per GPU |\n",
    "| Scaling | Scale all workers together | Scale prefill/decode independently |\n",
    "| Complexity | Simpler | More complex coordination |\n",
    "| Latency | Lower for small batches | Better for large throughput |\n",
    "| Resource Usage | More flexible | More optimized |\n",
    "\n",
    "**In this lab:**\n",
    "We're using disaggregated serving with a small model (1.5B) primarily for **educational purposes** to demonstrate the architecture pattern. In production, you would typically use aggregated serving for models this size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get the node IP\n",
    "NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}')\n",
    "\n",
    "echo \"Node IP: $NODE_IP\"\n",
    "echo \"\"\n",
    "echo \"Frontend URL: http://$NODE_IP:30100\"\n",
    "echo \"\"\n",
    "echo \"‚úì Access the frontend at: http://$NODE_IP:30100\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd540f3",
   "metadata": {},
   "source": [
    "### Step 2: Test the `/v1/models` Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get node IP\n",
    "NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}')\n",
    "\n",
    "# Test the /v1/models endpoint\n",
    "curl http://$NODE_IP:30100/v1/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265b713",
   "metadata": {},
   "source": [
    "### Step 3: Simple Non-Streaming Chat Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get node IP\n",
    "NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}')\n",
    "\n",
    "# Test non-streaming chat completion\n",
    "curl http://$NODE_IP:30100/v1/chat/completions \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello! How are you?\"}],\n",
    "    \"stream\": false,\n",
    "    \"max_tokens\": 50\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0277c",
   "metadata": {},
   "source": [
    "### Step 4: Test Streaming Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b909536",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get node IP\n",
    "NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}')\n",
    "\n",
    "# Test streaming chat completion\n",
    "curl http://$NODE_IP:30100/v1/chat/completions \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Write a short poem about AI\"}],\n",
    "    \"stream\": true,\n",
    "    \"max_tokens\": 100\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ac9e2",
   "metadata": {},
   "source": [
    "### Step 5: Test with Different Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get node IP\n",
    "NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}')\n",
    "\n",
    "# Test with different parameters\n",
    "curl http://$NODE_IP:30100/v1/chat/completions \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "    \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain quantum computing in one sentence\"}],\n",
    "    \"stream\": false,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 100,\n",
    "    \"top_p\": 0.9\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7ebdd",
   "metadata": {},
   "source": [
    "## Section 5: Benchmarking with AI-Perf\n",
    "\n",
    "### Objectives\n",
    "- Install and configure AI-Perf benchmarking tool\n",
    "- Run performance benchmarks against your Kubernetes deployment\n",
    "- Analyze throughput, latency, and token metrics\n",
    "- Compare performance across different configurations\n",
    "\n",
    "### Metrics to Measure\n",
    "- Throughput (requests/second, tokens/second)\n",
    "- Latency (TTFT - Time To First Token, TPOT - Time Per Output Token, end-to-end)\n",
    "- GPU utilization\n",
    "- KV cache efficiency\n",
    "\n",
    "### Benchmarking Setup\n",
    "You'll run AI-Perf from your local machine against the port-forwarded service, simulating:\n",
    "- Different concurrency levels (fixed concurrent requests)\n",
    "- Request rate patterns (requests per second)\n",
    "- Various workload characteristics\n",
    "\n",
    "### Step 1: Install AI-Perf (if not already installed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d12ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Ensure pip is available in the venv\n",
    "print(\"Setting up pip in venv...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"ensurepip\", \"--default-pip\"], \n",
    "               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "# Install AI-Perf in the venv\n",
    "print(\"Installing AI-Perf...\")\n",
    "result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"aiperf\", \"-q\"])\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì AI-Perf installed successfully\")\n",
    "    # Verify aiperf can be imported\n",
    "    verify = subprocess.run([sys.executable, \"-c\", \"import aiperf\"], capture_output=True)\n",
    "    if verify.returncode == 0:\n",
    "        print(\"  aiperf is ready to use\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Installation had issues, but may still work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76b33c",
   "metadata": {},
   "source": [
    "### Step 2: Run Baseline Benchmark (Low Concurrency)\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT: Run benchmarks in a TERMINAL, not in notebook cells (aiperf can crash the kernel).**\n",
    "\n",
    "**To run this benchmark:**\n",
    "\n",
    "1. Open a new terminal (File ‚Üí New ‚Üí Terminal in JupyterLab)\n",
    "2. Copy and paste this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/dynamo-grove-brev/lab1 && ./run-benchmark.sh baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce621e0",
   "metadata": {},
   "source": [
    "This will run a low concurrency benchmark (1 concurrent request, 100 total requests) and display metrics including:\n",
    "- Time to First Token (TTFT)\n",
    "- Token throughput\n",
    "- Request latency\n",
    "- Percentile distributions (p50, p90, p99)\n",
    "\n",
    "### Step 3: Run Benchmark with Higher Concurrency\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT: Run benchmarks in a TERMINAL, not in notebook cells.**\n",
    "\n",
    "**To run this benchmark:**\n",
    "\n",
    "1. Open a new terminal (File ‚Üí New ‚Üí Terminal in JupyterLab)\n",
    "2. Copy and paste this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/dynamo-grove-brev/lab1 && ./run-benchmark.sh high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9824d",
   "metadata": {},
   "source": [
    "This will run a high concurrency benchmark (4 concurrent requests, 200 total requests) to stress test the system and see how it handles multiple simultaneous users.\n",
    "\n",
    "### Step 4: Run Benchmark with Request Rate\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT: Run benchmarks in a TERMINAL, not in notebook cells.**\n",
    "\n",
    "**To run this benchmark:**\n",
    "\n",
    "1. Open a new terminal (File ‚Üí New ‚Üí Terminal in JupyterLab)\n",
    "2. Copy and paste this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c41d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/dynamo-grove-brev/lab1 && ./run-benchmark.sh rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41898cff",
   "metadata": {},
   "source": [
    "This will run a request rate benchmark (10 requests per second, 200 total requests) to simulate a steady stream of users hitting the API at a controlled rate.\n",
    "\n",
    "### Step 5: Analyze Results\n",
    "\n",
    "Review the benchmark outputs above. Key metrics to look for:\n",
    "- **Throughput**: requests/second and tokens/second\n",
    "- **TTFT (Time To First Token)**: How quickly does the first token appear?\n",
    "- **TPOT (Time Per Output Token)**: Generation speed\n",
    "- **End-to-end latency**: Total request time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34472bde",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "When you're done with Lab 1, clean up your deployment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# Delete the deployment\n",
    "kubectl delete dynamographdeployment vllm-disagg-router -n $NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"‚úì Deployment deleted\"\n",
    "echo \"Verifying pods are terminating:\"\n",
    "kubectl get pods -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace47fd7",
   "metadata": {},
   "source": [
    "**Note:** Keep your namespace and platform for Lab 2! Only delete the deployment, not the namespace.\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Check Pod Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6191d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# Check all pods in your namespace\n",
    "kubectl get pods -n $NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"# To describe a specific pod to see errors:\"\n",
    "echo \"# kubectl describe pod <pod-name> -n $NAMESPACE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63dd55",
   "metadata": {},
   "source": [
    "### View Pod Logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db275a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# View logs from a specific component\n",
    "echo \"Frontend logs:\"\n",
    "kubectl logs -l component=Frontend -n $NAMESPACE --tail=50\n",
    "\n",
    "echo \"\"\n",
    "echo \"Worker logs:\"\n",
    "kubectl logs -l component=VllmDecodeWorker -n $NAMESPACE --tail=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15034448",
   "metadata": {},
   "source": [
    "### Check Deployment Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19049dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# Check DynamoGraphDeployment status\n",
    "echo \"DynamoGraphDeployment status:\"\n",
    "kubectl describe dynamographdeployment vllm-disagg-router -n $NAMESPACE\n",
    "\n",
    "echo \"\"\n",
    "echo \"Operator logs:\"\n",
    "kubectl logs -l app.kubernetes.io/name=dynamo-operator -n $NAMESPACE --tail=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b60e1",
   "metadata": {},
   "source": [
    "### Check Recent Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffe34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "NAMESPACE=${NAMESPACE:-dynamo}\n",
    "\n",
    "# View recent events in your namespace\n",
    "kubectl get events -n $NAMESPACE --sort-by=.lastTimestamp | tail -20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29e891",
   "metadata": {},
   "source": [
    "### Common Issues\n",
    "\n",
    "1. **ImagePullBackOff**: Check if you have access to NGC containers. Verify image version is correct.\n",
    "2. **Pods stuck in Pending**: Check if GPU resources are available: `kubectl describe pod <pod-name> -n $NAMESPACE`\n",
    "3. **Model download slow**: First run takes longer due to model download. Check worker logs for progress.\n",
    "4. **Port forward not working**: Make sure pods are `1/1 Ready` before forwarding. Kill existing port-forward processes: `pkill -f port-forward`\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What You Learned\n",
    "- ‚úÖ How to set up a namespace-scoped Dynamo deployment on Kubernetes\n",
    "- ‚úÖ Kubernetes-based disaggregated deployment architecture\n",
    "- ‚úÖ Creating and managing DynamoGraphDeployment resources\n",
    "- ‚úÖ Backend engine deployment (vLLM)\n",
    "- ‚úÖ Testing with OpenAI-compatible API\n",
    "- ‚úÖ Performance benchmarking with AI-Perf\n",
    "\n",
    "### Key Takeaways\n",
    "- Namespace-scoped operators enable safe multi-tenant deployments\n",
    "- Disaggregated serving separates prefill and decode for optimized resource utilization\n",
    "- KV-cache routing provides intelligent load balancing across replicas\n",
    "- DynamoGraphDeployment CRD simplifies complex inference deployments\n",
    "- AI-Perf provides comprehensive performance insights\n",
    "\n",
    "### Next Steps\n",
    "- **(Optional)** Complete the **Monitoring Extension** (`lab1-monitoring.md`) to set up Prometheus and Grafana for observability\n",
    "- In **Lab 2**, you'll explore advanced optimizations and use AIConfigurator to optimize configurations for larger models\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix: Step-by-Step Commands\n",
    "\n",
    "This appendix provides complete commands for each section. Use these as a reference during the lab.\n",
    "\n",
    "**Note for MicroK8s users:** Replace `kubectl` with `microk8s kubectl` in all commands below, or set up an alias:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "alias kubectl='microk8s kubectl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f36af",
   "metadata": {},
   "source": [
    "### A1. Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7192be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Verify kubectl is installed and configured\n",
    "kubectl version --client\n",
    "kubectl cluster-info\n",
    "\n",
    "# Set your configuration\n",
    "export NAMESPACE=\"dynamo\"\n",
    "export RELEASE_VERSION=\"0.7.1\"     # Dynamo version\n",
    "export HF_TOKEN=\"your_hf_token\"    # Your HuggingFace token\n",
    "export CACHE_PATH=\"/data/huggingface-cache\"  # Shared cache path\n",
    "\n",
    "# Create your personal namespace\n",
    "kubectl create namespace ${NAMESPACE}\n",
    "\n",
    "# Verify namespace was created\n",
    "kubectl get namespace ${NAMESPACE}\n",
    "\n",
    "# Check GPU nodes are available (optional)\n",
    "kubectl get nodes -o custom-columns=NAME:.metadata.name,GPUs:.status.capacity.nvidia\\\\.com/gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ab545",
   "metadata": {},
   "source": [
    "### A2. Install Dynamo Platform (Namespace-Scoped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Step 1: Check if CRDs are already installed (cluster-wide)\n",
    "if kubectl get crd dynamographdeployments.nvidia.com &>/dev/null && \\\n",
    "   kubectl get crd dynamocomponentdeployments.nvidia.com &>/dev/null; then\n",
    "    echo \"‚úì CRDs already installed\"\n",
    "else\n",
    "    echo \"‚ö†Ô∏è  CRDs not found. Ask instructor to install them, or run:\"\n",
    "    echo \"helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-crds-${RELEASE_VERSION}.tgz\"\n",
    "    echo \"helm install dynamo-crds dynamo-crds-${RELEASE_VERSION}.tgz --namespace default\"\n",
    "fi\n",
    "\n",
    "# Step 2: Download Dynamo platform helm chart\n",
    "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-platform-${RELEASE_VERSION}.tgz\n",
    "\n",
    "# Step 3: Install namespace-scoped Dynamo platform\n",
    "# IMPORTANT: --set dynamo-operator.namespaceRestriction.enabled=true restricts operator to this namespace\n",
    "helm install dynamo-platform dynamo-platform-${RELEASE_VERSION}.tgz \\\n",
    "  --namespace ${NAMESPACE} \\\n",
    "  --set dynamo-operator.namespaceRestriction.enabled=true\n",
    "\n",
    "# Step 4: Wait for platform pods to be ready (~2-3 minutes)\n",
    "echo \"Waiting for platform pods to be ready...\"\n",
    "kubectl wait --for=condition=ready pod \\\n",
    "  --all \\\n",
    "  --namespace ${NAMESPACE} \\\n",
    "  --timeout=300s\n",
    "\n",
    "# Step 5: Verify platform is running\n",
    "kubectl get pods -n ${NAMESPACE}\n",
    "# You should see: dynamo-operator, etcd, and nats pods in Running state\n",
    "\n",
    "# Step 6: Create HuggingFace token secret\n",
    "kubectl create secret generic hf-token-secret \\\n",
    "  --from-literal=HF_TOKEN=\"${HF_TOKEN}\" \\\n",
    "  --namespace ${NAMESPACE}\n",
    "\n",
    "# Verify secret was created\n",
    "kubectl get secret hf-token-secret -n ${NAMESPACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc7255",
   "metadata": {},
   "source": [
    "### A3. Deploy Your First Model\n",
    "\n",
    "Create a deployment YAML file `disagg_router.yaml`:\n",
    "\n",
    "```yaml\n",
    "# disagg_router.yaml\n",
    "apiVersion: nvidia.com/v1alpha1\n",
    "kind: DynamoGraphDeployment\n",
    "metadata:\n",
    "  name: vllm-disagg-router\n",
    "spec:\n",
    "  services:\n",
    "    Frontend:\n",
    "      dynamoNamespace: vllm-disagg-router\n",
    "      componentType: frontend\n",
    "      replicas: 1\n",
    "      extraPodSpec:\n",
    "        mainContainer:\n",
    "          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.5.0\n",
    "      envs:\n",
    "        - name: DYN_ROUTER_MODE\n",
    "          value: disaggregated\n",
    "    VllmPrefillWorker:\n",
    "      envFromSecret: hf-token-secret\n",
    "      dynamoNamespace: vllm-disagg-router\n",
    "      componentType: worker\n",
    "      replicas: 1\n",
    "      resources:\n",
    "        limits:\n",
    "          gpu: \"1\"\n",
    "      envs:\n",
    "        - name: DYN_LOG\n",
    "          value: \"info\"\n",
    "      extraPodSpec:\n",
    "        volumes:\n",
    "        - name: local-model-cache\n",
    "          hostPath:\n",
    "            path: /data/huggingface-cache  # Update if instructor provides different path\n",
    "            type: DirectoryOrCreate\n",
    "        mainContainer:\n",
    "          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.5.0\n",
    "          securityContext:\n",
    "            capabilities:\n",
    "              add:\n",
    "                - IPC_LOCK\n",
    "          volumeMounts:\n",
    "          - name: local-model-cache\n",
    "            mountPath: /root/.cache\n",
    "          workingDir: /workspace/components/backends/vllm\n",
    "          command:\n",
    "            - /bin/sh\n",
    "            - -c\n",
    "          args:\n",
    "            - python3 -m dynamo.vllm --model Qwen/Qwen2.5-1.5B-Instruct --worker-type prefill\n",
    "    VllmDecodeWorker:\n",
    "      envFromSecret: hf-token-secret\n",
    "      dynamoNamespace: vllm-disagg-router\n",
    "      componentType: worker\n",
    "      replicas: 1\n",
    "      resources:\n",
    "        limits:\n",
    "          gpu: \"1\"\n",
    "      envs:\n",
    "        - name: DYN_LOG\n",
    "          value: \"info\"\n",
    "      extraPodSpec:\n",
    "        volumes:\n",
    "        - name: local-model-cache\n",
    "          hostPath:\n",
    "            path: /data/huggingface-cache  # Update if instructor provides different path\n",
    "            type: DirectoryOrCreate\n",
    "        mainContainer:\n",
    "          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.5.0\n",
    "          securityContext:\n",
    "            capabilities:\n",
    "              add:\n",
    "                - IPC_LOCK\n",
    "          volumeMounts:\n",
    "          - name: local-model-cache\n",
    "            mountPath: /root/.cache\n",
    "          workingDir: /workspace/components/backends/vllm\n",
    "          command:\n",
    "            - /bin/sh\n",
    "            - -c\n",
    "          args:\n",
    "            - python3 -m dynamo.vllm --model Qwen/Qwen2.5-1.5B-Instruct --worker-type decode\n",
    "```\n",
    "\n",
    "Deploy the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Apply the deployment\n",
    "kubectl apply -f disagg_router.yaml --namespace ${NAMESPACE}\n",
    "\n",
    "# Monitor deployment progress\n",
    "kubectl get dynamographdeployment -n ${NAMESPACE}\n",
    "\n",
    "# Watch pods starting up (this takes 4-6 minutes for first run)\n",
    "kubectl get pods -n ${NAMESPACE} -w\n",
    "# Press Ctrl+C to stop watching\n",
    "\n",
    "# Check specific pod status\n",
    "kubectl get pods -n ${NAMESPACE} | grep vllm\n",
    "\n",
    "# View worker logs to see model loading progress\n",
    "WORKER_POD=$(kubectl get pods -n ${NAMESPACE} | grep vllmdecodeworker | head -1 | awk '{print $1}')\n",
    "kubectl logs ${WORKER_POD} -n ${NAMESPACE} --tail=50 --follow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e44da7",
   "metadata": {},
   "source": [
    "### A4. Test the Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eaf3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# The frontend is exposed via NodePort on port 30100\n",
    "# Get the node IP\n",
    "NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}')\n",
    "\n",
    "echo \"Frontend URL: http://$NODE_IP:30100\"\n",
    "echo \"\"\n",
    "echo \"Quick test commands (run in terminal):\"\n",
    "echo \"\"\n",
    "echo \"# Test 1: Check available models\"\n",
    "echo \"curl http://$NODE_IP:30100/v1/models\"\n",
    "echo \"\"\n",
    "echo \"# Test 2: Simple chat completion\"\n",
    "echo \"curl http://$NODE_IP:30100/v1/chat/completions -H 'Content-Type: application/json' -d '{\\\"model\\\": \\\"Qwen/Qwen2.5-1.5B-Instruct\\\", \\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hello!\\\"}], \\\"stream\\\": false, \\\"max_tokens\\\": 50}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252a14c",
   "metadata": {},
   "source": [
    "### A5. Benchmark with AI-Perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9005e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Get node IP\n",
    "NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}')\n",
    "FRONTEND_URL=\"http://$NODE_IP:30100\"\n",
    "\n",
    "echo \"Benchmarking frontend at: $FRONTEND_URL\"\n",
    "echo \"\"\n",
    "\n",
    "# Install AI-Perf (if not already installed)\n",
    "pip install aiperf -q\n",
    "\n",
    "echo \"=== Running benchmarks ===\"\n",
    "echo \"\"\n",
    "\n",
    "# Run a simple benchmark (adjust parameters as needed)\n",
    "echo \"1. Low concurrency benchmark...\"\n",
    "aiperf profile     --log-level warning     --model Qwen/Qwen2.5-1.5B-Instruct     --url $FRONTEND_URL     --endpoint-type chat     --streaming     --concurrency 1     --request-count 100\n",
    "\n",
    "# Run with higher concurrency\n",
    "echo \"\"\n",
    "echo \"2. High concurrency benchmark...\"\n",
    "aiperf profile     --log-level warning     --model Qwen/Qwen2.5-1.5B-Instruct     --url $FRONTEND_URL     --endpoint-type chat     --streaming     --concurrency 4     --request-count 200\n",
    "\n",
    "# Run with request rate\n",
    "echo \"\"\n",
    "echo \"3. Request rate benchmark...\"\n",
    "aiperf profile     --log-level warning     --model Qwen/Qwen2.5-1.5B-Instruct     --url $FRONTEND_URL     --endpoint-type chat     --streaming     --request-rate 10     --request-count 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513f814",
   "metadata": {},
   "source": [
    "### A6. Scale Your Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Edit your disagg_router.yaml and change replicas from 1 to 2\n",
    "# Then reapply:\n",
    "kubectl apply -f disagg_router.yaml --namespace ${NAMESPACE}\n",
    "\n",
    "# Watch the new worker come online\n",
    "kubectl get pods -n ${NAMESPACE} -w\n",
    "\n",
    "# Test that load is distributed (KV-cache routing should work)\n",
    "# Run multiple requests and check logs from both workers\n",
    "kubectl logs -l component=VllmDecodeWorker -n ${NAMESPACE} --tail=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d2cd5",
   "metadata": {},
   "source": [
    "### A7. Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3121b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Delete the deployment\n",
    "kubectl delete dynamographdeployment vllm-disagg-router -n ${NAMESPACE}\n",
    "\n",
    "# Verify pods are terminating\n",
    "kubectl get pods -n ${NAMESPACE}\n",
    "\n",
    "# (Optional) Keep your namespace for Lab 2\n",
    "# To completely clean up (only if you're done with all labs):\n",
    "# kubectl delete namespace ${NAMESPACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c9096",
   "metadata": {},
   "source": [
    "### A8. Troubleshooting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a32b8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check pod status\n",
    "kubectl get pods -n ${NAMESPACE}\n",
    "\n",
    "# Describe a pod to see errors\n",
    "kubectl describe pod <pod-name> -n ${NAMESPACE}\n",
    "\n",
    "# View logs from a specific pod\n",
    "kubectl logs <pod-name> -n ${NAMESPACE}\n",
    "\n",
    "# Check DynamoGraphDeployment status\n",
    "kubectl describe dynamographdeployment vllm-disagg-router -n ${NAMESPACE}\n",
    "\n",
    "# Check operator logs\n",
    "kubectl logs -l app.kubernetes.io/name=dynamo-operator -n ${NAMESPACE}\n",
    "\n",
    "# Check if image pull is working\n",
    "kubectl get events -n ${NAMESPACE} --sort-by='.lastTimestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b9155",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python",
   "notebook_metadata_filter": "jupytext,-kernelspec,-widgets,-language_info"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
